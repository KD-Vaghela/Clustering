{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "K MEANS CLUSTERING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn import metrics\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.cluster import KMeansClusterer,cosine_distance\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn import mixture\n",
    "import numpy as np\n",
    "from collections import OrderedDict\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "import gensim\n",
    "from gensim import corpora\n",
    "from gensim.models import CoherenceModel\n",
    "# Add your import statement\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Would you rather get a gift that you knew what...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Is the internet ruining people's ability to co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Permanganate?\\r\\nSuppose permanganate was used...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>If Rock-n-Roll is really the work of the devil...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Has anyone purchased software to watch TV on y...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text\n",
       "0  Would you rather get a gift that you knew what...\n",
       "1  Is the internet ruining people's ability to co...\n",
       "2  Permanganate?\\r\\nSuppose permanganate was used...\n",
       "3  If Rock-n-Roll is really the work of the devil...\n",
       "4  Has anyone purchased software to watch TV on y..."
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>No desire to visit mother in jail, am I a bad ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7</td>\n",
       "      <td>what types of desirable products/materials can...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>what is teleportation? why an unknown indian i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>Do you have to read the whole Bible to get int...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>6 yr old son with a Deviated Septum!!!!?\\r\\nMy...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label                                               text\n",
       "0      3  No desire to visit mother in jail, am I a bad ...\n",
       "1      7  what types of desirable products/materials can...\n",
       "2      2  what is teleportation? why an unknown indian i...\n",
       "3      1  Do you have to read the whole Bible to get int...\n",
       "4      3  6 yr old son with a Deviated Septum!!!!?\\r\\nMy..."
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "train = pd.read_csv(\"D:/clustering/Train_Data.csv\")\n",
    "train.head()\n",
    "\n",
    "test = pd.read_csv(\"D:/clustering/Test_Data.csv\")\n",
    "test.head()\n",
    "\n",
    "test_text = test[\"text\"]\n",
    "test_label = test[\"label\"]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Defined a function `cluster_kmean(train_text, test_text, text_label)` as follows:\n",
    "- Take three inputs: \n",
    "    - `train_text` is a list of documents for traing \n",
    "    - `test_text` is a list of documents for test\n",
    "    - `test_label` is the labels corresponding to documents in `test_text` \n",
    "- First step- Creates a TFIDF weights\n",
    "- Uses `KMeans` to cluster documents in `train_text` into 4 clusters. \n",
    "    \n",
    "- Tests the clustering model performance using `test_label` as follows: \n",
    "  - Predicts the cluster ID for each document in `test_text`.\n",
    "  - `majority vote` rule is applied to dynamically map the predicted cluster IDs to `test_label`. \n",
    "  - Print out the cross tabluation between cluster ids and class labels\n",
    "  - print out the classification report for the test subset \n",
    "  \n",
    "  \n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cluster_kmean(train, test_text, test_label):\n",
    "    tfidf = TfidfVectorizer(stop_words=\"english\",min_df=2)\n",
    "    tfidf_matrix = tfidf.fit_transform(train)\n",
    "    \n",
    "    #****COSINE DISTANCE****\n",
    "    \n",
    "    clusterer = KMeansClusterer(4, cosine_distance, repeats=30)\n",
    "    clusters = clusterer.cluster(tfidf_matrix.toarray(), assign_clusters=True)\n",
    "    centroids=np.array(clusterer.means())\n",
    "    sorted_centroids = centroids.argsort()[:, ::-1] \n",
    "    voc_lookup= tfidf.get_feature_names_out()\n",
    "    num_clusters = 4\n",
    "    for i in range(num_clusters):\n",
    "        top_words=[voc_lookup[word_index] for word_index in sorted_centroids[i, :20]]\n",
    "        print(\"Cluster %d:\\n %s \" % (i, \"; \".join(top_words)))\n",
    "    test_tfidf_matrix = tfidf.transform(test_text)\n",
    "    predicted_cluster = [clusterer.classify(x) for x in test_tfidf_matrix.toarray()]\n",
    "    confusion_df = pd.DataFrame(list(zip(test_label.values, predicted_cluster)), columns = [\"actual_class\", \"cluster\"])\n",
    "    crosstab = pd.crosstab( index=confusion_df.cluster, columns=confusion_df.actual_class)\n",
    "    crosstab_idx = crosstab.idxmax(axis = 0)\n",
    "    crosstab_idx = crosstab_idx.sort_values(ascending=True) \n",
    "    labels_name=[]\n",
    "    cluster_idx = []\n",
    "    for x,y in crosstab_idx.iteritems():\n",
    "        labels_name.append(x)\n",
    "        cluster_idx.append(y)\n",
    "\n",
    "    cluster_dctnry = dict(zip(cluster_idx,labels_name))\n",
    "    print(cluster_dctnry)\n",
    "    predicted_target=[cluster_dctnry[i] for i in predicted_cluster]\n",
    "    #print(predicted_target)\n",
    "    print('FOR COSINE')\n",
    "    print(crosstab)\n",
    "    print(metrics.classification_report(test_label, predicted_target,zero_division = 0))\n",
    "    \n",
    "    #****EUCLIDEAN DISTANCE****\n",
    "    \n",
    "    km = KMeans(n_clusters=4, n_init=30).fit(tfidf_matrix)\n",
    "    clusters_eu = km.labels_.tolist()\n",
    "    test_tfidf_matrix = tfidf.transform(test_text)\n",
    "    predicted_clusters_eu = km.predict(test_tfidf_matrix)\n",
    "    confusion_df_eu = pd.DataFrame(list(zip(test_label.values, predicted_clusters_eu)),columns = [\"actual_class\", \"cluster\"])\n",
    "    crosstab_eu = pd.crosstab( index=confusion_df_eu.cluster, columns=confusion_df_eu.actual_class)\n",
    "    \n",
    "    crosstab_idx_eu = crosstab_eu.idxmax(axis = 1)\n",
    "    #crosstab_idx_eu = crosstab_idx_eu.sort_values(ascending=True) \n",
    "    labels_name_eu=[]\n",
    "    cluster_idx_eu = []\n",
    "    for x,y in crosstab_idx_eu.iteritems():\n",
    "        labels_name_eu.append(y)\n",
    "        cluster_idx_eu.append(x)\n",
    "\n",
    "    cluster_dctnry_eu = dict(zip(cluster_idx_eu, labels_name_eu))\n",
    "    print(cluster_dctnry_eu)\n",
    "    predicted_target_eu=[cluster_dctnry_eu[i] for i in predicted_clusters_eu]\n",
    "    \n",
    "    print('FOR EUCLIDEAN')\n",
    "    print(crosstab_eu)\n",
    "    print(metrics.classification_report(test_label, predicted_target_eu, zero_division = 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster 0:\n",
      " water; energy; light; earth; number; mass; nthe; air; speed; 10; used; gas; sun; force; equation; heat; space; does; universe; cell \n",
      "Cluster 1:\n",
      " com; job; business; money; www; credit; work; nhttp; pay; good; want; company; need; help; know; don; like; http; looking; home \n",
      "Cluster 2:\n",
      " like; just; know; don; help; people; think; weight; time; really; good; want; need; body; feel; day; make; doctor; life; eat \n",
      "Cluster 3:\n",
      " god; people; jesus; bible; believe; religion; christians; think; just; christian; church; world; like; life; know; question; man; does; don; say \n",
      "{0: 2, 1: 7, 2: 3, 3: 1}\n",
      "FOR COSINE\n",
      "actual_class    1    2    3    7\n",
      "cluster                         \n",
      "0               6  214   12    5\n",
      "1              39   33   20  212\n",
      "2              93   56  319   44\n",
      "3             194   11    4   12\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.88      0.58      0.70       332\n",
      "           2       0.90      0.68      0.78       314\n",
      "           3       0.62      0.90      0.74       355\n",
      "           7       0.70      0.78      0.73       273\n",
      "\n",
      "    accuracy                           0.74      1274\n",
      "   macro avg       0.78      0.74      0.74      1274\n",
      "weighted avg       0.77      0.74      0.74      1274\n",
      "\n",
      "{0: 2, 1: 1, 2: 3, 3: 3}\n",
      "FOR EUCLIDEAN\n",
      "actual_class    1    2    3    7\n",
      "cluster                         \n",
      "0             105  285  124  178\n",
      "1             100    3    3    1\n",
      "2               0    0   55    1\n",
      "3             127   26  173   93\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.93      0.30      0.46       332\n",
      "           2       0.41      0.91      0.57       314\n",
      "           3       0.48      0.64      0.55       355\n",
      "           7       0.00      0.00      0.00       273\n",
      "\n",
      "    accuracy                           0.48      1274\n",
      "   macro avg       0.46      0.46      0.39      1274\n",
      "weighted avg       0.48      0.48      0.41      1274\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cluster_kmean(train[\"text\"], test_text, test_label)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Clustering by Gaussian Mixture Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cluster_gmm(train, test_text, test_label):\n",
    "    tfidf = TfidfVectorizer(stop_words=\"english\",min_df=5)\n",
    "    tfidf_matrix = tfidf.fit_transform(train)\n",
    "    \n",
    "    number_of_clusters = 4\n",
    "    covariance_types =  'diag'\n",
    "    gmm = mixture.GaussianMixture(n_components= number_of_clusters,\n",
    "                                      covariance_type=covariance_types,random_state= 32, n_init= 30)\n",
    "    gmm.fit(tfidf_matrix.toarray())\n",
    "    bic = gmm.bic(tfidf_matrix.toarray())    \n",
    "    \n",
    "    print(bic)\n",
    "    print(gmm)\n",
    "    test_tfidf_matrix = tfidf.transform(test_text)\n",
    "\n",
    "    predicted = gmm.predict(test_tfidf_matrix.toarray())\n",
    "   \n",
    "    confusion_df = pd.DataFrame(list(zip(test_label.values, predicted)),columns = [\"actual_class\", \"cluster\"])\n",
    "    print(pd.crosstab( index=confusion_df.cluster, columns=confusion_df.actual_class))\n",
    "    cr = pd.crosstab( index=confusion_df.cluster, columns=confusion_df.actual_class)\n",
    "    crosstab_idx = cr.idxmax(axis = 1)\n",
    "    #print(crosstab_idx)\n",
    "    crosstab_idx = crosstab_idx.sort_values(ascending=True) \n",
    "    labels_name=[]\n",
    "    cluster_idx = []\n",
    "    for x,y in crosstab_idx.iteritems():\n",
    "        labels_name.append(y)\n",
    "        cluster_idx.append(x)\n",
    "\n",
    "    cluster_dctnry = dict(zip(cluster_idx,labels_name))\n",
    "    cl_dic = OrderedDict(sorted(cluster_dctnry.items()))\n",
    "    #print(cl_dic)\n",
    "   \n",
    "    predicted_target=[cl_dic[i] for i in predicted]\n",
    "    print(metrics.classification_report      (test_label, predicted_target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-213115521.69835934\n",
      "GaussianMixture(covariance_type='diag', n_components=4, n_init=30,\n",
      "                random_state=32)\n",
      "actual_class    1    2    3    7\n",
      "cluster                         \n",
      "0              11   18  244   20\n",
      "1             231   15   49   34\n",
      "2              20    9   14  159\n",
      "3              70  272   48   60\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.70      0.70      0.70       332\n",
      "           2       0.60      0.87      0.71       314\n",
      "           3       0.83      0.69      0.75       355\n",
      "           7       0.79      0.58      0.67       273\n",
      "\n",
      "    accuracy                           0.71      1274\n",
      "   macro avg       0.73      0.71      0.71      1274\n",
      "weighted avg       0.73      0.71      0.71      1274\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cluster_gmm(train[\"text\"], test_text, test_label)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clustering by LDA\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cluster_lda(train, test_text, test_label):\n",
    "    tf_vectorizer = CountVectorizer(min_df=5, stop_words='english')\n",
    "    tf = tf_vectorizer.fit_transform(train)\n",
    "    tf_feature_names = tf_vectorizer.get_feature_names_out()\n",
    "    test_tfidf_matrix = tf_vectorizer.transform(test_text)\n",
    "    num_topics = 4\n",
    "    lda = LatentDirichletAllocation(n_components=num_topics,                                 max_iter=40,verbose=1,\n",
    "                                evaluate_every=1, n_jobs=1,\n",
    "                                random_state=2).fit(tf)\n",
    "    number_of_top_words=30\n",
    "    for topic_idx, topic in enumerate(lda.components_):\n",
    "        print (\"Topic %d:\" % (topic_idx))\n",
    "    \n",
    "        words=[(tf_feature_names[i]) for i in topic.argsort()[::-1][0:number_of_top_words]]\n",
    "        print(words)\n",
    "        print(\"\\n\")\n",
    "    tranform_test_tfidf = lda.transform(test_tfidf_matrix)\n",
    "    tranform_test_tfidf_df = pd.DataFrame(tranform_test_tfidf)\n",
    "    predicted_topic =  tranform_test_tfidf_df.idxmax(axis = 1)\n",
    "    confusion_df = pd.DataFrame(list(zip(test_label, predicted_topic)),                            columns = [\"actual_class\", \"cluster\"])\n",
    "    cr = pd.crosstab( index=confusion_df.cluster, columns=confusion_df.actual_class)\n",
    "    print(cr)\n",
    "    majority_vote_lda = cr.idxmax(axis=1).to_dict()\n",
    "    predicted_target_lda = [majority_vote_lda[i] for i in predicted_topic]\n",
    "    print(metrics.classification_report      (test_label, predicted_target_lda))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration: 1 of max_iter: 40, perplexity: 3345.6230\n",
      "iteration: 2 of max_iter: 40, perplexity: 3110.1062\n",
      "iteration: 3 of max_iter: 40, perplexity: 2935.3820\n",
      "iteration: 4 of max_iter: 40, perplexity: 2811.3937\n",
      "iteration: 5 of max_iter: 40, perplexity: 2726.2071\n",
      "iteration: 6 of max_iter: 40, perplexity: 2661.6236\n",
      "iteration: 7 of max_iter: 40, perplexity: 2609.6799\n",
      "iteration: 8 of max_iter: 40, perplexity: 2570.9029\n",
      "iteration: 9 of max_iter: 40, perplexity: 2543.0075\n",
      "iteration: 10 of max_iter: 40, perplexity: 2521.5307\n",
      "iteration: 11 of max_iter: 40, perplexity: 2504.1573\n",
      "iteration: 12 of max_iter: 40, perplexity: 2489.9569\n",
      "iteration: 13 of max_iter: 40, perplexity: 2477.9848\n",
      "iteration: 14 of max_iter: 40, perplexity: 2468.1776\n",
      "iteration: 15 of max_iter: 40, perplexity: 2460.0644\n",
      "iteration: 16 of max_iter: 40, perplexity: 2453.9584\n",
      "iteration: 17 of max_iter: 40, perplexity: 2449.3203\n",
      "iteration: 18 of max_iter: 40, perplexity: 2445.5774\n",
      "iteration: 19 of max_iter: 40, perplexity: 2442.0304\n",
      "iteration: 20 of max_iter: 40, perplexity: 2438.7711\n",
      "iteration: 21 of max_iter: 40, perplexity: 2436.0553\n",
      "iteration: 22 of max_iter: 40, perplexity: 2433.8556\n",
      "iteration: 23 of max_iter: 40, perplexity: 2432.1362\n",
      "iteration: 24 of max_iter: 40, perplexity: 2430.6037\n",
      "iteration: 25 of max_iter: 40, perplexity: 2429.1529\n",
      "iteration: 26 of max_iter: 40, perplexity: 2427.8263\n",
      "iteration: 27 of max_iter: 40, perplexity: 2426.6667\n",
      "iteration: 28 of max_iter: 40, perplexity: 2425.5731\n",
      "iteration: 29 of max_iter: 40, perplexity: 2424.5093\n",
      "iteration: 30 of max_iter: 40, perplexity: 2423.5267\n",
      "iteration: 31 of max_iter: 40, perplexity: 2422.7095\n",
      "iteration: 32 of max_iter: 40, perplexity: 2421.9572\n",
      "iteration: 33 of max_iter: 40, perplexity: 2421.3244\n",
      "iteration: 34 of max_iter: 40, perplexity: 2420.7483\n",
      "iteration: 35 of max_iter: 40, perplexity: 2420.0869\n",
      "iteration: 36 of max_iter: 40, perplexity: 2419.4006\n",
      "iteration: 37 of max_iter: 40, perplexity: 2418.6931\n",
      "iteration: 38 of max_iter: 40, perplexity: 2417.8723\n",
      "iteration: 39 of max_iter: 40, perplexity: 2417.0038\n",
      "iteration: 40 of max_iter: 40, perplexity: 2416.0626\n",
      "Topic 0:\n",
      "['water', 'nthe', 'energy', '10', 'light', 'number', 'earth', 'air', 'used', 'does', 'mass', 'gas', 'answer', 'speed', 'force', 'time', 'na', 'sun', 'pressure', 'equation', 'heat', 'use', 'space', 'like', 'high', 'form', 'know', 'cell', 'temperature', 'point']\n",
      "\n",
      "\n",
      "Topic 1:\n",
      "['com', 'good', 'www', 'want', 'need', 'work', 'money', 'business', 'help', 'know', 'job', 'like', 'nhttp', 'make', 'don', 'time', 'pay', 'credit', 'just', 'http', 'company', 'way', 'people', 'weight', 'best', 'year', 'information', 'home', 'free', 'years']\n",
      "\n",
      "\n",
      "Topic 2:\n",
      "['god', 'people', 'think', 'just', 'like', 'life', 'question', 'know', 'believe', 'jesus', 'world', 'don', 'say', 'bible', 'does', 'man', 'time', 'religion', 'way', 'love', 'did', 'person', 'answers', 'christians', 'word', 'good', 'things', 'really', 'true', 'ni']\n",
      "\n",
      "\n",
      "Topic 3:\n",
      "['just', 'like', 'don', 'help', 'know', 'body', 'time', 'people', 'think', 'really', 'good', 'feel', 'need', 'want', 'make', 'doctor', 'blood', 'does', 'way', 'day', 'pain', 'going', 'use', 've', 'work', 'try', 'things', 'cause', 'weight', 'long']\n",
      "\n",
      "\n",
      "actual_class    1    2    3    7\n",
      "cluster                         \n",
      "0               3  208    3    6\n",
      "1              33   36   28  216\n",
      "2             247   25    9   16\n",
      "3              49   45  315   35\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.83      0.74      0.79       332\n",
      "           2       0.95      0.66      0.78       314\n",
      "           3       0.71      0.89      0.79       355\n",
      "           7       0.69      0.79      0.74       273\n",
      "\n",
      "    accuracy                           0.77      1274\n",
      "   macro avg       0.79      0.77      0.77      1274\n",
      "weighted avg       0.80      0.77      0.77      1274\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cluster_lda(train[\"text\"], test_text, test_label)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "555eaf241af5f9a809a201f9d625964ebf1eff8d1e4c1ca64115e0f26c96cfdb"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

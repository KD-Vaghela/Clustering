{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "K MEANS CLUSTERING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn import metrics\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.cluster import KMeansClusterer,cosine_distance\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn import mixture\n",
    "import numpy as np\n",
    "from collections import OrderedDict\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "import gensim\n",
    "from gensim import corpora\n",
    "from gensim.models import CoherenceModel\n",
    "# Add your import statement\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train = pd.read_csv(\"D:/clustering/Train_Data.csv\")\n",
    "train.head()\n",
    "\n",
    "test = pd.read_csv(\"D:/clustering/Test_Data.csv\")\n",
    "test.head()\n",
    "\n",
    "test_text = test[\"text\"]\n",
    "test_label = test[\"label\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cluster_kmean(train, test_text, test_label):\n",
    "    tfidf = TfidfVectorizer(stop_words=\"english\",min_df=2)\n",
    "    tfidf_matrix = tfidf.fit_transform(train)\n",
    "    \n",
    "    #****COSINE DISTANCE****\n",
    "    \n",
    "    clusterer = KMeansClusterer(4, cosine_distance, repeats=30)\n",
    "    clusters = clusterer.cluster(tfidf_matrix.toarray(), assign_clusters=True)\n",
    "    centroids=np.array(clusterer.means())\n",
    "    sorted_centroids = centroids.argsort()[:, ::-1] \n",
    "    voc_lookup= tfidf.get_feature_names_out()\n",
    "    num_clusters = 4\n",
    "    for i in range(num_clusters):\n",
    "        top_words=[voc_lookup[word_index] for word_index in sorted_centroids[i, :20]]\n",
    "        print(\"Cluster %d:\\n %s \" % (i, \"; \".join(top_words)))\n",
    "    test_tfidf_matrix = tfidf.transform(test_text)\n",
    "    predicted_cluster = [clusterer.classify(x) for x in test_tfidf_matrix.toarray()]\n",
    "    confusion_df = pd.DataFrame(list(zip(test_label.values, predicted_cluster)), columns = [\"actual_class\", \"cluster\"])\n",
    "    crosstab = pd.crosstab( index=confusion_df.cluster, columns=confusion_df.actual_class)\n",
    "    crosstab_idx = crosstab.idxmax(axis = 0)\n",
    "    crosstab_idx = crosstab_idx.sort_values(ascending=True) \n",
    "    labels_name=[]\n",
    "    cluster_idx = []\n",
    "    for x,y in crosstab_idx.iteritems():\n",
    "        labels_name.append(x)\n",
    "        cluster_idx.append(y)\n",
    "\n",
    "    cluster_dctnry = dict(zip(cluster_idx,labels_name))\n",
    "    print(cluster_dctnry)\n",
    "    predicted_target=[cluster_dctnry[i] for i in predicted_cluster]\n",
    "    #print(predicted_target)\n",
    "    print('FOR COSINE')\n",
    "    print(crosstab)\n",
    "    print(metrics.classification_report(test_label, predicted_target))\n",
    "    \n",
    "    #****EUCLIDEAN DISTANCE****\n",
    "    \n",
    "    km = KMeans(n_clusters=4, n_init=30).fit(tfidf_matrix)\n",
    "    clusters_eu = km.labels_.tolist()\n",
    "    test_tfidf_matrix = tfidf.transform(test_text)\n",
    "    predicted_clusters_eu = km.predict(test_tfidf_matrix)\n",
    "    confusion_df_eu = pd.DataFrame(list(zip(test_label.values, predicted_clusters_eu)),columns = [\"actual_class\", \"cluster\"])\n",
    "    crosstab_eu = pd.crosstab( index=confusion_df_eu.cluster, columns=confusion_df_eu.actual_class)\n",
    "    \n",
    "    crosstab_idx_eu = crosstab_eu.idxmax(axis = 1)\n",
    "    #crosstab_idx_eu = crosstab_idx_eu.sort_values(ascending=True) \n",
    "    labels_name_eu=[]\n",
    "    cluster_idx_eu = []\n",
    "    for x,y in crosstab_idx_eu.iteritems():\n",
    "        labels_name_eu.append(y)\n",
    "        cluster_idx_eu.append(x)\n",
    "\n",
    "    cluster_dctnry_eu = dict(zip(cluster_idx_eu, labels_name_eu))\n",
    "    print(cluster_dctnry_eu)\n",
    "    predicted_target_eu=[cluster_dctnry_eu[i] for i in predicted_clusters_eu]\n",
    "    \n",
    "    print('FOR EUCLIDEAN')\n",
    "    print(crosstab_eu)\n",
    "    print(metrics.classification_report(test_label, predicted_target_eu))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Admin\\Anaconda\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster 0:\n",
      " water; energy; light; earth; number; nthe; 10; mass; used; air; speed; gas; force; sun; equation; space; answer; does; universe; heat \n",
      "Cluster 1:\n",
      " com; business; money; job; www; credit; nhttp; work; pay; company; want; good; need; help; http; know; like; don; home; looking \n",
      "Cluster 2:\n",
      " help; weight; like; just; don; know; body; doctor; good; need; eat; time; really; want; day; blood; pain; diet; feel; fat \n",
      "Cluster 3:\n",
      " god; people; think; just; like; life; jesus; believe; know; bible; don; love; religion; say; person; time; man; christians; question; way \n",
      "{0: 2, 1: 7, 2: 3, 3: 1}\n",
      "FOR COSINE\n",
      "actual_class    1    2    3    7\n",
      "cluster                         \n",
      "0               7  214    5    7\n",
      "1              36   29   18  206\n",
      "2              24   47  297   24\n",
      "3             265   24   35   36\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.74      0.80      0.77       332\n",
      "           2       0.92      0.68      0.78       314\n",
      "           3       0.76      0.84      0.80       355\n",
      "           7       0.71      0.75      0.73       273\n",
      "\n",
      "    accuracy                           0.77      1274\n",
      "   macro avg       0.78      0.77      0.77      1274\n",
      "weighted avg       0.78      0.77      0.77      1274\n",
      "\n",
      "{0: 2, 1: 1, 2: 3, 3: 3}\n",
      "FOR EUCLIDEAN\n",
      "actual_class    1    2    3    7\n",
      "cluster                         \n",
      "0             114  288  126  196\n",
      "1             100    3    3    1\n",
      "2             118   23  176   75\n",
      "3               0    0   50    1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.93      0.30      0.46       332\n",
      "           2       0.40      0.92      0.55       314\n",
      "           3       0.51      0.64      0.57       355\n",
      "           7       0.00      0.00      0.00       273\n",
      "\n",
      "    accuracy                           0.48      1274\n",
      "   macro avg       0.46      0.46      0.39      1274\n",
      "weighted avg       0.48      0.48      0.41      1274\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Admin\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\Admin\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\Admin\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "cluster_kmean(train[\"text\"], test_text, test_label)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gaussian Mixture Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cluster_gmm(train, test_text, test_label):\n",
    "    tfidf = TfidfVectorizer(stop_words=\"english\",min_df=5)\n",
    "    tfidf_matrix = tfidf.fit_transform(train)\n",
    "    \n",
    "    number_of_clusters = 4\n",
    "    covariance_types =  'diag'\n",
    "    gmm = mixture.GaussianMixture(n_components= number_of_clusters,\n",
    "                                      covariance_type=covariance_types,random_state= 32, n_init= 30)\n",
    "    gmm.fit(tfidf_matrix.toarray())\n",
    "    bic = gmm.bic(tfidf_matrix.toarray())    \n",
    "    \n",
    "    print(bic)\n",
    "    print(gmm)\n",
    "    test_tfidf_matrix = tfidf.transform(test_text)\n",
    "\n",
    "    predicted = gmm.predict(test_tfidf_matrix.toarray())\n",
    "   \n",
    "    confusion_df = pd.DataFrame(list(zip(test_label.values, predicted)),columns = [\"actual_class\", \"cluster\"])\n",
    "    print(pd.crosstab( index=confusion_df.cluster, columns=confusion_df.actual_class))\n",
    "    cr = pd.crosstab( index=confusion_df.cluster, columns=confusion_df.actual_class)\n",
    "    crosstab_idx = cr.idxmax(axis = 1)\n",
    "    #print(crosstab_idx)\n",
    "    crosstab_idx = crosstab_idx.sort_values(ascending=True) \n",
    "    labels_name=[]\n",
    "    cluster_idx = []\n",
    "    for x,y in crosstab_idx.iteritems():\n",
    "        labels_name.append(y)\n",
    "        cluster_idx.append(x)\n",
    "\n",
    "    cluster_dctnry = dict(zip(cluster_idx,labels_name))\n",
    "    cl_dic = OrderedDict(sorted(cluster_dctnry.items()))\n",
    "    #print(cl_dic)\n",
    "   \n",
    "    predicted_target=[cl_dic[i] for i in predicted]\n",
    "    print(metrics.classification_report      (test_label, predicted_target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-213115521.69835934\n",
      "GaussianMixture(covariance_type='diag', n_components=4, n_init=30,\n",
      "                random_state=32)\n",
      "actual_class    1    2    3    7\n",
      "cluster                         \n",
      "0              11   18  244   20\n",
      "1             231   15   49   34\n",
      "2              20    9   14  159\n",
      "3              70  272   48   60\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.70      0.70      0.70       332\n",
      "           2       0.60      0.87      0.71       314\n",
      "           3       0.83      0.69      0.75       355\n",
      "           7       0.79      0.58      0.67       273\n",
      "\n",
      "    accuracy                           0.71      1274\n",
      "   macro avg       0.73      0.71      0.71      1274\n",
      "weighted avg       0.73      0.71      0.71      1274\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cluster_gmm(train[\"text\"], test_text, test_label)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LDA\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cluster_lda(train, test_text, test_label):\n",
    "    tf_vectorizer = CountVectorizer(min_df=5, stop_words='english')\n",
    "    tf = tf_vectorizer.fit_transform(train)\n",
    "    tf_feature_names = tf_vectorizer.get_feature_names_out()\n",
    "    test_tfidf_matrix = tf_vectorizer.transform(test_text)\n",
    "    num_topics = 4\n",
    "    lda = LatentDirichletAllocation(n_components=num_topics,                                 max_iter=40,verbose=1,\n",
    "                                evaluate_every=1, n_jobs=1,\n",
    "                                random_state=2).fit(tf)\n",
    "    number_of_top_words=30\n",
    "    for topic_idx, topic in enumerate(lda.components_):\n",
    "        print (\"Topic %d:\" % (topic_idx))\n",
    "    \n",
    "        words=[(tf_feature_names[i]) for i in topic.argsort()[::-1][0:number_of_top_words]]\n",
    "        print(words)\n",
    "        print(\"\\n\")\n",
    "    tranform_test_tfidf = lda.transform(test_tfidf_matrix)\n",
    "    tranform_test_tfidf_df = pd.DataFrame(tranform_test_tfidf)\n",
    "    predicted_topic =  tranform_test_tfidf_df.idxmax(axis = 1)\n",
    "    confusion_df = pd.DataFrame(list(zip(test_label, predicted_topic)),                            columns = [\"actual_class\", \"cluster\"])\n",
    "    cr = pd.crosstab( index=confusion_df.cluster, columns=confusion_df.actual_class)\n",
    "    print(cr)\n",
    "    majority_vote_lda = cr.idxmax(axis=1).to_dict()\n",
    "    predicted_target_lda = [majority_vote_lda[i] for i in predicted_topic]\n",
    "    print(metrics.classification_report      (test_label, predicted_target_lda))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration: 1 of max_iter: 40, perplexity: 3345.6230\n",
      "iteration: 2 of max_iter: 40, perplexity: 3110.1062\n",
      "iteration: 3 of max_iter: 40, perplexity: 2935.3820\n",
      "iteration: 4 of max_iter: 40, perplexity: 2811.3937\n",
      "iteration: 5 of max_iter: 40, perplexity: 2726.2071\n",
      "iteration: 6 of max_iter: 40, perplexity: 2661.6236\n",
      "iteration: 7 of max_iter: 40, perplexity: 2609.6799\n",
      "iteration: 8 of max_iter: 40, perplexity: 2570.9029\n",
      "iteration: 9 of max_iter: 40, perplexity: 2543.0075\n",
      "iteration: 10 of max_iter: 40, perplexity: 2521.5307\n",
      "iteration: 11 of max_iter: 40, perplexity: 2504.1573\n",
      "iteration: 12 of max_iter: 40, perplexity: 2489.9569\n",
      "iteration: 13 of max_iter: 40, perplexity: 2477.9848\n",
      "iteration: 14 of max_iter: 40, perplexity: 2468.1776\n",
      "iteration: 15 of max_iter: 40, perplexity: 2460.0644\n",
      "iteration: 16 of max_iter: 40, perplexity: 2453.9584\n",
      "iteration: 17 of max_iter: 40, perplexity: 2449.3203\n",
      "iteration: 18 of max_iter: 40, perplexity: 2445.5774\n",
      "iteration: 19 of max_iter: 40, perplexity: 2442.0304\n",
      "iteration: 20 of max_iter: 40, perplexity: 2438.7711\n",
      "iteration: 21 of max_iter: 40, perplexity: 2436.0553\n",
      "iteration: 22 of max_iter: 40, perplexity: 2433.8556\n",
      "iteration: 23 of max_iter: 40, perplexity: 2432.1362\n",
      "iteration: 24 of max_iter: 40, perplexity: 2430.6037\n",
      "iteration: 25 of max_iter: 40, perplexity: 2429.1529\n",
      "iteration: 26 of max_iter: 40, perplexity: 2427.8263\n",
      "iteration: 27 of max_iter: 40, perplexity: 2426.6667\n",
      "iteration: 28 of max_iter: 40, perplexity: 2425.5731\n",
      "iteration: 29 of max_iter: 40, perplexity: 2424.5093\n",
      "iteration: 30 of max_iter: 40, perplexity: 2423.5267\n",
      "iteration: 31 of max_iter: 40, perplexity: 2422.7095\n",
      "iteration: 32 of max_iter: 40, perplexity: 2421.9572\n",
      "iteration: 33 of max_iter: 40, perplexity: 2421.3244\n",
      "iteration: 34 of max_iter: 40, perplexity: 2420.7483\n",
      "iteration: 35 of max_iter: 40, perplexity: 2420.0869\n",
      "iteration: 36 of max_iter: 40, perplexity: 2419.4006\n",
      "iteration: 37 of max_iter: 40, perplexity: 2418.6931\n",
      "iteration: 38 of max_iter: 40, perplexity: 2417.8723\n",
      "iteration: 39 of max_iter: 40, perplexity: 2417.0038\n",
      "iteration: 40 of max_iter: 40, perplexity: 2416.0626\n",
      "Topic 0:\n",
      "['water', 'nthe', 'energy', '10', 'light', 'number', 'earth', 'air', 'used', 'does', 'mass', 'gas', 'answer', 'speed', 'force', 'time', 'na', 'sun', 'pressure', 'equation', 'heat', 'use', 'space', 'like', 'high', 'form', 'know', 'cell', 'temperature', 'point']\n",
      "\n",
      "\n",
      "Topic 1:\n",
      "['com', 'good', 'www', 'want', 'need', 'work', 'money', 'business', 'help', 'know', 'job', 'like', 'nhttp', 'make', 'don', 'time', 'pay', 'credit', 'just', 'http', 'company', 'way', 'people', 'weight', 'best', 'year', 'information', 'home', 'free', 'years']\n",
      "\n",
      "\n",
      "Topic 2:\n",
      "['god', 'people', 'think', 'just', 'like', 'life', 'question', 'know', 'believe', 'jesus', 'world', 'don', 'say', 'bible', 'does', 'man', 'time', 'religion', 'way', 'love', 'did', 'person', 'answers', 'christians', 'word', 'good', 'things', 'really', 'true', 'ni']\n",
      "\n",
      "\n",
      "Topic 3:\n",
      "['just', 'like', 'don', 'help', 'know', 'body', 'time', 'people', 'think', 'really', 'good', 'feel', 'need', 'want', 'make', 'doctor', 'blood', 'does', 'way', 'day', 'pain', 'going', 'use', 've', 'work', 'try', 'things', 'cause', 'weight', 'long']\n",
      "\n",
      "\n",
      "actual_class    1    2    3    7\n",
      "cluster                         \n",
      "0               3  208    3    6\n",
      "1              33   36   28  216\n",
      "2             247   25    9   16\n",
      "3              49   45  315   35\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.83      0.74      0.79       332\n",
      "           2       0.95      0.66      0.78       314\n",
      "           3       0.71      0.89      0.79       355\n",
      "           7       0.69      0.79      0.74       273\n",
      "\n",
      "    accuracy                           0.77      1274\n",
      "   macro avg       0.79      0.77      0.77      1274\n",
      "weighted avg       0.80      0.77      0.77      1274\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cluster_lda(train[\"text\"], test_text, test_label)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12 (main, Apr  4 2022, 05:22:27) [MSC v.1916 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "555eaf241af5f9a809a201f9d625964ebf1eff8d1e4c1ca64115e0f26c96cfdb"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
